{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Churn Prediction with PySpark using MLlib and ML Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check version of python\n",
    "\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source: https://www.mapr.com/blog/churn-prediction-pyspark-using-mllib-and-ml-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set Matplotlib inline plotting and load Pandas package\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.options.display.mpl_style = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, HiveContext, Row\n",
    "\n",
    "hive_ctx = HiveContext(sc)\n",
    "hive_ctx.setConf(\"hive.exec.dynamic.partition\", \"true\")\n",
    "hive_ctx.setConf(\"hive.exec.dynamic.partition.mode\", \"nonstrict\")\n",
    "hive_ctx.setConf(\"hive.exec.max.dynamic.partitions\", \"10000\")\n",
    "hive_ctx.sql(\"SET spark.sql.parquet.compression.codec=snappy\") \n",
    "\n",
    "hive_ctx.sql(\"use prod_dxbreach_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data \n",
    "\n",
    "Churn_data = hive_ctx.sql(\"Select * from bi_churnanalysistable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the first 5 results\n",
    "\n",
    "pd.DataFrame(Churn_data.take(5), columns=Churn_data.columns).transpose() \n",
    "\n",
    "# Same thing but without transpose (less easy to read)\n",
    "\n",
    " # pd.DataFrame(Churn_data.take(5), columns=Churn_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split between training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain the number of rows:\n",
    "Churn_data.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create pandas df\n",
    "Churn_data_Pandas = pd.DataFrame(Churn_data.take(56126), columns=Churn_data.columns) # take(total number of rows)\n",
    "\n",
    "# Split the data\n",
    "Churn_train = Churn_data_Pandas.sample(frac=0.8) \n",
    "Churn_test = Churn_data_Pandas.drop(Churn_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Churn_train.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cast ischurned as int\n",
    "\n",
    "Churn_train[['ischurned']] = Churn_train[['ischurned']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a look at the different types of data in Churn_data\n",
    "\n",
    "Churn_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep only int64 features\n",
    "\n",
    "cols = list(Churn_train.ix[:,3:8] + Churn_train.ix[:,9:17] + Churn_train.ix[:,18:31]) \n",
    "\n",
    "# Select a 10% sample\n",
    "\n",
    "Churn_train[cols].sample(frac=0.1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep only the numeric features\n",
    "\n",
    "# numeric_features = [t[0] for t in Churn_train.dtypes if t[1] == 'int64' or t[1] == 'float64'] \n",
    "\n",
    "# sampled_data = Churn_train.select(numeric_features).sample(False, 0.10).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Matrix of covariance\n",
    "\n",
    "sampled_data = Churn_train[cols].sample(frac=0.1) \n",
    "\n",
    "axs = pd.scatter_matrix(sampled_data, figsize=(12, 12)); \n",
    "\n",
    "# Rotate axis labels and remove axis ticks\n",
    "n = len(sampled_data.columns)\n",
    "for i in range(n):\n",
    "    v = axs[i, 0]\n",
    "    v.yaxis.label.set_rotation(0)\n",
    "    v.yaxis.label.set_ha('right')\n",
    "    v.set_yticks(())\n",
    "    h = axs[n-1, i]\n",
    "    h.xaxis.label.set_rotation(90)\n",
    "    h.set_xticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 1: Export to CSV and use R to determine which fields to drop (glm method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If on my computer: \n",
    "# pd.DataFrame.to_csv()\n",
    "# import os\n",
    "# path = 'C:\\Users\\mdeleseleuc\\Documents'\n",
    "# output_filename = 'Churn_train.csv'\n",
    "# Churn_train.to_csv(os.path.join(path,output_filename))\n",
    "\n",
    "# In the cluster:\n",
    "\n",
    "Churn_train_Spark = sqlContext.createDataFrame(Churn_train) # Convert Panda df to Spark df\n",
    "\n",
    "Churn_train_Spark.registerTempTable(\"mytempTableTrain\") # Create temporary table \n",
    "\n",
    "# sqlContext.sql(\"drop table mytable\")\n",
    "sqlContext.sql(\"create table if not exists mytableTrain as select * from mytempTable\") # create table in hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 2: Drop useless fields by hand (don't do that...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's get rid of highly correlated variables\n",
    "\n",
    "Churn_train = Churn_train.drop('lifespan').drop('daysincelastseen') \\\n",
    "             .drop('uniquemapcompleted').drop()\n",
    "\n",
    "Churn_train.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 3: Feature Selection using tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Source 1: http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\"\"\"Source 2: https://kaggle2.blob.core.windows.net/forum-message-attachments/44681/1286/\n",
    "kaggle_forest.py?sv=2012-02-12&se=2016-11-14T22%3A52%3A58Z&sr=b&sp=r&sig=vizTB90DrEljcgvjIGgVVkPowHxAs%2BKO%2BZmqCzf8lms%3D\"\"\"\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import ensemble\n",
    "\n",
    "# feature_cols = [col for col in Churn_train.columns if col in Churn_train[cols]]\n",
    "\n",
    "feature_cols = [col for col in Churn_train.columns if col not in ['s__uid','cohort','monthcohort','avgattemptspermap', \n",
    "                                                                  'successesfailsratio','ischurned']\n",
    "               ]\n",
    "\n",
    "X_train = Churn_train[feature_cols]\n",
    "y = Churn_train['ischurned']\n",
    "\n",
    "X_train.shape              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VÃ©rify that columns are the one we wanted\n",
    "\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of NaN values\n",
    "from sklearn.preprocessing import Imputer \n",
    "X_train = Imputer().fit_transform(X_train)\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "clf.fit(X_train, y)\n",
    "\n",
    "# Print the features importance (contribution to total variance)\n",
    "clf.feature_importances_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a look at the new shape\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X_train)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "\n",
    "# Source: http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "          #sphx-glr-auto-examples-ensemble-plot-forest-importances-py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "    \n",
    "\"\"\" Informative features =  'firstsessionduration','uniquemapsplayed', 'totalinfiltrations', 'successes', 'retries',\n",
    "                           'fails', 'lifespan',  'playerschallenges',  'weaponparts'\n",
    "\"\"\"\n",
    "# Total variance explained (with informative features) = 78% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reprocessing: Normalize the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source\n",
    "\n",
    "http://machinelearningmastery.com/rescaling-data-for-machine-learning-in-python-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using the Spark MLlib Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees require almost no data preparation (ie normalization) and can handle both categorical and continuous data.\n",
    "\n",
    "To remedy over-fitting and improve prediction accuracy, decision trees can also be limited to a certain depth or complexity, or bundled into ensembles of trees (ie random forests).\n",
    "\n",
    "A decision tree is a predictive model which maps observations (features) about an item to conclusions about the item's label or class. The model is generated using a top-down approach, where the source dataset is split into subsets using a statistical measure, often in the form of the Gini index or information gain via Shannon entropy. This process is applied recursively until a subset contains only samples with the same target class, or is halted by a predefined stopping criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLlib classifiers and regressors require data sets in a format of rows of type LabeledPoint, which separates row labels and feature lists, and names them accordingly. The custom labelData() function shown below performs the row parsing. We'll pass it the prepared data set (Churn_train) and split it further into training and testing sets. \n",
    "\n",
    "A decision tree classifier model is then generated using the training data, using a maxDepth of 2, to build a \"shallow\" tree. The tree depth can be regarded as an indicator of model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Move ischurned to the end \n",
    "\n",
    "Churn_train_map = Churn_train[feature_cols] # columns excluding categorical variables\n",
    "\n",
    "Churn_train_map['ischurned'] = Churn_train['ischurned'] # Add ischurned (at the end)\n",
    "\n",
    "# Did it work?\n",
    "Churn_train_map.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "\n",
    "# LabeledPoint is basically the structure saying which is your target variable (label) and your features vector\n",
    "\n",
    "def labelData(data):\n",
    "    # label: row[end], features: row[0:end-1]\n",
    "    return sqlContext.createDataFrame(data).map(lambda row: LabeledPoint(row[-1], row[:-1]))\n",
    "\n",
    "# sqlContext.createDataFrame(panda_df) = convert to spark_df\n",
    "       \n",
    "training_data, testing_data = labelData(Churn_train_map).randomSplit([0.8, 0.2])\n",
    "\n",
    "model = DecisionTree.trainClassifier(training_data, numClasses=2, \n",
    "                                     categoricalFeaturesInfo = {}, # variables are all continuous\n",
    "                                     impurity='gini', maxDepth=8, maxBins=32) #Max depth = model complexity\n",
    " \n",
    "print model.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The toDebugString() function provides a print of the tree's decision nodes and final prediction outcomes at the end leafs. \n",
    "\n",
    "We can see that features 10 and 16 are used for decision making and should thus be considered as having high predictive power to determine a customer's likeliness to churn. \n",
    "\n",
    "Decision trees are often used for feature selection because they provide an automated mechanism for determining the most important features (those closest to the tree root).\n",
    "\n",
    "N.B: in line with features selection above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sneak peak at the labeled data.\n",
    "\n",
    "training_data.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Feature 13:', Churn_train_map.columns[13]\n",
    "print 'Feature 15:', Churn_train_map.columns[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions of the testing data's churn outcome are made with the model's predict() function and grouped together with the actual churn label of each customer data using getPredictionsLabels().\n",
    "\n",
    "We'll use MLlib's MulticlassMetrics() for the model evaluation, which takes rows of (prediction, label) tuples as input. It provides metrics such as precision, recall, F1 score and confusion matrix, which have been bundled for printing with the custom printMetrics() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def getPredictionsLabels(model, test_data):\n",
    "    predictions = model.predict(test_data.map(lambda r: r.features))\n",
    "    return predictions.zip(test_data.map(lambda r: r.label))\n",
    "\n",
    "def printMetrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print 'Precision of True ', metrics.precision(1)\n",
    "    print 'Precision of False', metrics.precision(0)\n",
    "    print 'Recall of True    ', metrics.recall(1)\n",
    "    print 'Recall of False   ', metrics.recall(0)\n",
    "    print 'F-1 Score         ', metrics.fMeasure()\n",
    "    print 'Confusion Matrix\\n', metrics.confusionMatrix().toArray()\n",
    "\n",
    "predictions_and_labels = getPredictionsLabels(model, testing_data)\n",
    "\n",
    "printMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F-1 Score = Overall accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. \n",
    "The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. \n",
    "The recall is intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall (aka sensitivity) for the Churn=True samples is high, while the recall for the Churn=False examples is relatively low.\n",
    "\n",
    "Perhaps the model's sensitivity bias toward Churn= True samples is due to a skewed distribution of the two types of samples.\n",
    "\n",
    "Let's try grouping the Churn_train DataFrame by the ischurned field and counting the number of instances in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Churn_train.groupby('ischurned')['ischurned'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are roughly 7 times as many True churn samples as False churn samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put the two sample types on the same footing using stratified sampling. The DataFrames sampleBy() function does this when provided with fractions of each sample type to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Churn_train_strat = sqlContext.createDataFrame(Churn_train) # transform into PySpark dataset to be able to use sampleBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're keeping all instances of the Churn=False class, but downsampling the Churn=True class to a fraction of 5672/39229."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stratified_Churn_train = Churn_train_strat.sampleBy('ischurned', fractions={0:1.0, 1: 5672./39229}).cache()\n",
    "\n",
    "stratified_Churn_train.groupby('ischurned').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stratified_Churn_train.describe().toPandas().transpose() # 11,484 rows (reduced the number of true)\n",
    "\n",
    "# Convert dataset to dataframe\n",
    "\n",
    "stratified_Churn_train = pd.DataFrame(stratified_Churn_train.take(11484), columns=stratified_Churn_train.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Move ischurned to the end \n",
    "\n",
    "stratified_Churn_train_map = stratified_Churn_train[feature_cols] # columns excluding categorical variables\n",
    "\n",
    "stratified_Churn_train_map['ischurned'] = stratified_Churn_train['ischurned'] # Add ischurned (at the end)\n",
    "\n",
    "# Did it work?\n",
    "Churn_train_map.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the decision tree\n",
    "\n",
    "training_data, testing_data = labelData(stratified_Churn_train_map).randomSplit([0.8, 0.2])\n",
    "\n",
    "model = DecisionTree.trainClassifier(training_data, numClasses=2, \n",
    "                                     categoricalFeaturesInfo = {}, # variables are all continuous\n",
    "                                     impurity='gini', maxDepth=8, maxBins=32) #Max depth = model complexity\n",
    " \n",
    "print model.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluation its accuracy\n",
    "\n",
    "predictions_and_labels = getPredictionsLabels(model, testing_data)\n",
    "printMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stratified data was helpful in building a less biased model which will provide more generalized and robust predictions.\n",
    "\n",
    "But: accuracry greatly decreased!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
